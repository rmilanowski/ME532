---
title: "MeanShift"
author: "Ryan Milanowski"
date: "12/2/2019"
output: pdf_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(ggplot2)
library(dplyr)
```



```{r cars}
summary(iris)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
# We only need the two columns of data that we will be clustering
TestData <- iris %>% transmute(Petal.Length, Petal.Width)

# Scaling Data
TestData$Petal.Length <- (TestData$Petal.Length-mean(TestData$Petal.Length))/sd(TestData$Petal.Length)
TestData$Petal.Width <- (TestData$Petal.Width-mean(TestData$Petal.Width))/sd(TestData$Petal.Width)

TestDataMat <- t(TestData)

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r, meansift algorithm}
#meanshift algorithm

meanShiftOperator <- function( x, points, h=1,
kernel="epanechnikovKernel" ){
	
	## mean-shift operator
	
	## compute distances
	distances <- apply( points, 2, distanceFunction, y=x )
	
	## scale by bandwidth
	scaled.distances <- distances / h
	
	## evaluate kernel
	kernel <- get( kernel )
	kernel.values <- kernel( scaled.distances )
	
	## weights denominator
	total.sum <- sum( kernel.values )
	
	## mean-shift weights
	if( total.sum > 0 ){
		
		## update
		kernel.weights <- kernel.values / sum( kernel.values )
		output <- points %*% kernel.weights
		
	} else{
		
		output <- x
		
	}
	
	return( output )
	
}

###

meanShiftAlgorithm <- function( x, points, h=1, kernel="epanechnikovKernel",
tol.stop=1e-6 ){
	
	close.enough <- FALSE

	old.x <- x
	
	## while the trajectory has not converged
	## (update produced a shift larger than 'tol.stop')
	while( !close.enough ) {

		## apply mean-shift operator and update
		new.x <- meanShiftOperator( x=old.x, points=points, h=h,
		kernel=kernel )

		distance <- distanceFunction( old.x, new.x )

		old.x <- new.x

		close.enough <- ( distance < tol.stop )

	}
	
	return( new.x )
	
}

###

meanShiftAlgorithmAll <- function( X, h=NULL, kernel="epanechnikovKernel",
tol.stop=1e-6, multi.core=FALSE ){
	
	if( is.null( h ) ){
		
		h <- quantile( dist( t( X ) ), 0.3 )
		
	}
	
	if( multi.core ){
		
		## MULTICORE REQUIRES 'parallel' LIBRARY
				
		X.list <- lapply( apply( X, 2, list ), unlist )
		
		multi.core.output <- mclapply( X.list, meanShiftAlgorithm,
		points=X, h=h, kernel=kernel, tol.stop=tol.stop )
		
		output <- do.call( cbind, multi.core.output )
		
	} else{
		
		M <- X
		n <- ncol( X )
		
		pb <- txtProgressBar( min=0, max=n, style=3 )
		
		for( i in 1:n ){
			
			M[,i] <- meanShiftAlgorithm( x=X[,i], points=X, h=h,
			kernel=kernel, tol.stop=tol.stop )
			
			setTxtProgressBar( pb, i )
			
		}
		
		close( pb )
		
		output <- M
	
	}

	message( "\nMean-shift algorithm ran successfully.\n")
	
	return( output )
	
}

###

msClustering <- function( X, h=NULL, kernel="epanechnikovKernel",
tol.stop=1e-6, tol.epsilon=1e-3, multi.core=FALSE ){
	
	# minimal input checking
	X <- as.matrix( X )
		
	if( ncol( X ) <= 1 ){
		
		message( "The input matrix X has only one column: ",
		"returning input.")
		return( X )
	}
	
	if( !is.element( kernel, paste( c( "epanechnikov", "cubic", 
	"gaussian", "exponential"), "Kernel", sep="" ) ) ){
		
		stop( "Invalid kernel name.")
		
	}
	
	if( !is.null( h ) && h <= 0 ){
		
		stop( "The bandwidth must be strictly positive." )
		
	}
		
	if( tol.stop <= 0 || tol.epsilon <= 0 ){
		
		stop( "All tolerances must be strictly positive.")
		
	}
		
	## run mean-shift algorithm
	message( "\nRunning mean-shift algorithm...\n" )
	
	if( multi.core ){
		
		n.cores <- getOption( "mc.cores" )
		
		if( is.null( n.cores ) ){
			
			readInteger <- function(){
				
				n <- readline( "Enter number of cores: " )
				
				n <- as.integer( n )
				
				return( n )
				
			}
			
			n.cores <- readInteger()
			
			if( n.cores < 1 ){
				
				n.cores <- 1
				options( mc.cores=n.cores )
				
				cat( "\n" )
								
				warning( "\nInvalid choice for the number ",
				"of cores: 'mc.cores' option set to 1. To change, ",
				"use options( mc.cores=n ) where n is the desired ",
				"number of cores." )
				
			} else{
				
				options( mc.cores=n.cores )
				message( "\n'mc.cores' option set to ",
				as.character( n.cores ),".\n" )
				
			}
			
		}
		
		message( "Using ", as.character( n.cores ),
		" cores..." )
	
	}
			
	mean.shift.algorithm <- meanShiftAlgorithmAll( X=X, h=h,
	kernel=kernel, tol.stop=tol.stop, multi.core=multi.core )
	
	## find connected components
	message( "Finding clusters..." )
	output <- connectedComponents( X=mean.shift.algorithm,
	tol.epsilon=tol.epsilon )
	
	invisible( output )
	
}






```

```{r, auxilary}
gaussianKernel <- function( x ){
	
	## function to evaluate the asymmetric gaussian kernel	
	computeGaussianKernel <- function( y ){
	
		if( 0 <= y ){
		
			value <- 2 / 0.388 * dnorm( y / 0.388 )
		
		} else{
		
			value <- 0
		
		}
	
		return( value )
	
	}
	
	output <- sapply( x, computeGaussianKernel )
	
	return( output )
		
}


###

exponentialKernel <- function( x ){
	
	## function to evaluate the asymmetric exponential kernel	
	computeExponentialKernel <- function( y ){
	
		if( 0 <= y ){
		
			value <- dexp( y, rate=4.61 )
		
		} else{
		
			value <- 0
		
		}
	
		return( value )
	
	}
	
	output <- sapply( x, computeExponentialKernel )
	
	return( output )
		
}

###

cubicKernel <- function( x ){
	
	## function to evaluate the asymmetric cubic kernel	
	computeCubicKernel <- function( y ){
	
		if( 0 <= y && y<= 1 ){
		
			value <- 4 * ( 1 - y )^3
		
		} else{
		
			value <- 0
		
		}
	
		return( value )
	
	}
	
	output <- sapply( x, computeCubicKernel )
	
	return( output )
		
}

###

epanechnikovKernel <- function( x ){
	
	## function to evaluate the asymmetric Epanechnikov kernel	
	computeEpanechnikovKernel <- function( y ){
	
		if( 0 <= y && y<= 1 ){
		
			value <- 3 / 2 * ( 1 - y^2 )
		
		} else{
		
			value <- 0
		
		}
	
		return( value )
	
	}
	
	output <- sapply( x, computeEpanechnikovKernel )
	
	return( output )
		
}

###

distanceFunction <- function( x, y ){
	
	## function to compute the standard euclidean distance
	output <- sqrt( sum( ( x - y )^2 ) )
	
	return( output )
	
}

###

connectedComponents <- function( X, tol.epsilon=1e-3 ){

	N <- ncol( X )
	
	## initialize components matrix
	C <- X
	
	## initialize components vector
	labels <- vector( mode="integer", length=N )
	
	K <- 1 
	labels[1] <- 1
	C[,1] <- X[,1]
	
	# pb <- txtProgressBar( min=0, max=N, style=3 )
	
	## efficient connected component algorithm
	for( n in 2:N ){
		
		assigned <- FALSE
				
		for( k in 1:K ){
			
			distance <- distanceFunction( X[,n], C[,k] )
			
			if( distance < tol.epsilon ){
				
				labels[n] <- k
				assigned <- TRUE
				break
				
			}
			
		}
		
		if( !assigned ){
			
			K <- K + 1
			labels[n] <- K
			C[,K] <- X[,n]
			
		}
		
		# setTxtProgressBar( pb, n )
		
	}
	
	C <- as.matrix( C[,1:K] )
	colnames( C ) <- paste( "mode", 1:K, sep="" )
	
	labels <- as.integer( labels )
	
	output <- list( components=C, labels=labels )
	
	# close( pb )
	
	message( "\nThe algorithm found ", as.character( K ),
	" clusters.\n")
	
	return( output )
		
}


```

```{r, blurred meanshift}
blurringMeanShiftOperator <- function( X, h=1, kernel="epanechnikovKernel" ){
	
	n.curves <- ncol( X )
	
	## compute distances
	distances <- as.matrix( dist( t( X ), diag=TRUE, upper=TRUE ) )
	
	## scale by bandwidth
	scaled.distances <- distances / h
	
	## evaluate kernel
	kernel <- get( kernel )
	kernel.values <- matrix( kernel( scaled.distances ), nrow=n.curves,
	ncol=n.curves ) 
	
	## weights denominators
	total.sum <- colSums( kernel.values )
	
	## weights
	kernel.weights <- kernel.values / total.sum

	## update
	new.X <- X%*%t( kernel.weights )
	
	output <- new.X
	
	return( new.X )
	
}

blurringMeanShiftAlgorithm <- function( X, h=NULL,
kernel="epanechnikovKernel", tol.stop=1e-6, max.iter=100 ){
	
	if( is.null( h ) ){
		
		h <- quantile( dist( t( X ) ), 0.3 )
		
	}
	
	close.enough <- FALSE
	
	old.X <- X
	
	iter <- 0
	not.converged <- FALSE
	
	## while the largest update corresponds to a shift
	## larger than 'tol.stop' and while number of iterations
	## is smaller than 'max.iter'
	while( !close.enough ){
		
		## apply blurring mean-shift operator and update
		iter <- iter + 1
		
		new.X <- blurringMeanShiftOperator( X=old.X, h=h, kernel=kernel )
		
		distance <- max( sqrt( colSums( old.X - new.X )^2 ) )
		
		old.X <- new.X
		
		close.enough <- ( distance < tol.stop )
		
		if( iter >= max.iter ){
			
			not.converged <- TRUE
			break
			
		}
		
	}
	
	if( not.converged ){
		
		if( kernel == "epanechnikovKernel"){
			
			warning( "Reached maximum number of iterations (", 
			as.character( max.iter),"). The algorithm ",
			"didn't converge. Try increasing max.iter." )
			
		} else{

			warning( "Reached maximum number of iterations (", 
			as.character( max.iter),"). The algorithm ",
			"didn't converge. Try kernel=\"epanechnikovKernel\"." )
			
		}
		
	} else{

		message( "Blurring mean-shift algorithm ran successfully.\n")
			
	}
	
	return( new.X )
	
}

bmsClustering <- function( X, h=NULL, kernel="epanechnikovKernel",
tol.stop=1e-6, max.iter=100, tol.epsilon=1e-3 ){
	
	# minimal input checking
	X <- as.matrix( X )
	max.iter <- as.integer( max.iter )
	
	if( ncol( X ) <= 1 ){
		
		message( "The input matrix X has only one column: ",
		"returning input.")
		return( X )
	}

	if( !is.element( kernel, paste( c( "epanechnikov", "cubic", 
	"gaussian", "exponential"), "Kernel", sep="" ) ) ){
		
		stop( "Invalid kernel name.")
		
	}
	
	if( !is.null( h ) && h <= 0 ){
		
		stop( "The bandwidth must be strictly positive." )
				
	}
	
	if( max.iter <= 0 ){
		
		stop( "The maximum number of iterations must be a positive ",
		"integer." )
		
	}
	
	if( tol.stop <= 0 || tol.epsilon <= 0 ){
		
		stop( "All tolerances must be strictly positive.")
		
	}
	
	## run blurring mean-shift algorithm
	message( "\nRunning blurring mean-shift algorithm...\n" )
	
	blurring.mean.shift.algorithm <- blurringMeanShiftAlgorithm( X=X,
	h=h, kernel=kernel, tol.stop=tol.stop, max.iter=max.iter )
	
	## find connected components
	message( "Finding clusters..." )
	output <- connectedComponents( X=blurring.mean.shift.algorithm,
	tol.epsilon=tol.epsilon )
	
	invisible( output )

}


```



```{r}
#set.seed(1)
# Set Parameters
K <- 2           # Number of clusters
MaxIter <- 10     # Maximum number of kmeans iterations



X <- TestDataMat
h <- .8
kernel <- "epanechnikovKernel" #"epanechnikovKernel", "cubicKernel", "gaussianKernel", "exponentialKernel"
tol.stop <- 1e-6
tol.epsilon <- 1e-04
multi.core <- FALSE
max.iter <- 100


clust <- kmeans(TestData, centers = K, iter.max = MaxIter)
clust_ms <- bmsClustering(X = X,
                         h=h,
                         kernel = kernel,
                         tol.stop = tol.stop,
                         tol.epsilon = tol.epsilon,
                         max.iter = max.iter)

TestData2 <- iris
TestData2$cluster <- as.factor(clust$cluster)

TestData3 <- iris
TestData3$cluster <- as.factor(clust_ms$labels)
```


```{r}

ggplot(TestData2) +
    geom_point(aes(x = Petal.Length, y = Petal.Width, color = cluster)) +
    labs(x = "Petal Length", y = "Petal Width", title = "Iris Clustering",
         color = "Cluster") + 
    scale_color_brewer(palette = "Dark2")

ggplot(TestData3) +
    geom_point(aes(x = Petal.Length, y = Petal.Width, color = cluster)) +
    labs(x = "Petal Length", y = "Petal Width", title = "Iris Clustering",
         color = "Cluster") + 
    scale_color_brewer(palette = "Dark2")

```



```{r}
Data <- read.csv("Wisconsin.csv")

# Reducing data set to only clustering parameters
CongressData <- Data %>% transmute(LATITUDE, LONGITUDE)
# Scaling Data
CongressData$LATITUDE <- (CongressData$LATITUDE-mean(CongressData$LATITUDE))/sd(CongressData$LATITUDE)
CongressData$LONGITUDE <- (CongressData$LONGITUDE-mean(CongressData$LONGITUDE))/sd(CongressData$LONGITUDE)
CongressDataMat <- t(CongressData)

# Set Input Values
K = 8
IterMax = 5



# Run K-Means Algorithm
CongressCluster <- kmeans(CongressData, centers = K, iter.max = IterMax)

X <- CongressDataMat
h <- 1
kernel <- "epanechnikovKernel" #"epanechnikovKernel", "cubicKernel", "gaussianKernel", "exponentialKernel"
tol.stop <- 1e-10
tol.epsilon <- 1e-04
multi.core <- FALSE
max.iter <- 100


Congress_clust_ms <- bmsClustering(X = X,
                         h=h,
                         kernel = kernel,
                         tol.stop = tol.stop,
                         tol.epsilon = tol.epsilon,
                         max.iter = max.iter)
```



```{r}
# Unscale data for plotting and extract clusters associated with each Census tract
PlotCongressData <- Data %>% transmute(LATITUDE, LONGITUDE, POPULATION)
PlotCongressData$cluster <- CongressCluster$cluster

# Create dataframe for plotting cluster centers
Centers <- as.data.frame(CongressCluster$centers)
Centers$LATITUDE <- Centers$LATITUDE*sd(PlotCongressData$LATITUDE) + mean(PlotCongressData$LATITUDE)
Centers$LONGITUDE <- Centers$LONGITUDE*sd(PlotCongressData$LONGITUDE) + mean(PlotCongressData$LONGITUDE)
Centers$cluster <- 1:K

# Unscale data for plotting and extract clusters associated with each Census tract
PlotCongressDataMS <- Data %>% transmute(LATITUDE, LONGITUDE, POPULATION)
PlotCongressDataMS$cluster <- Congress_clust_ms$labels

# Create dataframe for plotting cluster centers
#CentersMS <- as.data.frame(Congress_clust_ms$assignment)
#CentersMS$LATITUDE <- CentersMS$LATITUDE*sd(PlotCongressDataMS$LATITUDE) + mean(PlotCongressDataMS$LATITUDE)
#CentersMS$LONGITUDE <- CentersMS$LONGITUDE*sd(PlotCongressDataMS$LONGITUDE) + mean(PlotCongressDataMS$LONGITUDE)
#CentersMS$cluster <- 1:length(unique(Congress_clust_ms$assignment))


ggplot() +
    geom_point(data = PlotCongressData,
               aes(x = LONGITUDE, y = LATITUDE, color = as.factor(cluster)),
               alpha = 1/2, size = 1) +
    geom_point(data = Centers,
               aes(x = LONGITUDE, y = LATITUDE, color = as.factor(cluster)),
               alpha = 1/2, size = 4) +
    labs(x = "Longitude (deg)", y = "Latitude (deg)", title = "Wisconsin Congressional Districts",
         subtitle = "K-Means Clustering",
         color = "Clustered District") + 
    theme_minimal() +
    scale_color_brewer(palette = "Set1")

ggplot() +
    geom_point(data = PlotCongressDataMS,
               aes(x = LONGITUDE, y = LATITUDE, color = as.factor(cluster)),
               alpha = 1/2, size = 1) +
    #geom_point(data = Centers,
     #          aes(x = LONGITUDE, y = LATITUDE, color = as.factor(cluster)),
      #         alpha = 1/2, size = 4) +
    labs(x = "Longitude (deg)", y = "Latitude (deg)", title = "Wisconsin Congressional Districts",
         subtitle = "Mean SHift Clustering",
         color = "Clustered District") +
    theme_minimal() #+
    #scale_color_brewer(palette = "Set1")

```






